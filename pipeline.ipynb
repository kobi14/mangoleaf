{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network using Augmentor and Keras\n",
    "\n",
    "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We start by making a number of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network\n",
    "\n",
    "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
    "\n",
    "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "input_shape = (300, 300, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view a summary of the network using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 296, 296, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 148, 148, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 148, 148, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1401856)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               179437696 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 179,458,576\n",
      "Trainable params: 179,458,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the MNIST data has downloaded, we can instantiate a `Pipeline` object in the `training` directory to add the images to the current pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 310 image(s) found.\n",
      "Output directory set to versi0/train/versi0_basicaugment/train."
     ]
    }
   ],
   "source": [
    "#p = Augmentor.Pipeline(\"versi0\")\n",
    "# Passing the path of the image directory \n",
    "p = Augmentor.Pipeline(source_directory=\"versi0/train\",\n",
    "                      output_directory=\"versi0_basicaugment/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Operations to the Pipeline\n",
    "\n",
    "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=500x333 at 0x166212250>: 100%|██████████| 620/620 [00:17<00:00, 35.72 Samples/s]                   \n"
     ]
    }
   ],
   "source": [
    "# Passing the path of the image directory \n",
    "\n",
    "  \n",
    "# Defining augmentation parameters and generating 10 samples \n",
    "p.flip_left_right(probability=0.4) \n",
    "p.flip_top_bottom(probability=0.8)\n",
    "p.rotate(probability=0.5, max_left_rotation=5, max_right_rotation=10)\n",
    "p.skew(0.4, 0.5) \n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5) \n",
    "p.sample(620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 5\n",
      "\t0: Flip (probability=0.4 top_bottom_left_right=LEFT_RIGHT )\n",
      "\t1: Flip (probability=0.8 top_bottom_left_right=TOP_BOTTOM )\n",
      "\t2: RotateRange (probability=0.5 max_left_rotation=-5 max_right_rotation=10 )\n",
      "\t3: Skew (probability=0.4 skew_type=RANDOM magnitude=0.5 )\n",
      "\t4: Zoom (probability=0.2 min_factor=1.1 max_factor=1.5 )\n",
      "Images: 310\n",
      "Classes: 16\n",
      "\tClass index: 0 Class label: apoderus_javanicus \n",
      "\tClass index: 1 Class label: aulacaspis_tubercularis \n",
      "\tClass index: 2 Class label: ceroplastes_rubens \n",
      "\tClass index: 3 Class label: cisaberoptus_kenyae \n",
      "\tClass index: 4 Class label: dappula_tertia \n",
      "\tClass index: 5 Class label: dialeuropora_decempuncta \n",
      "\tClass index: 6 Class label: erosomyia_sp \n",
      "\tClass index: 7 Class label: icerya_seychellarum \n",
      "\tClass index: 8 Class label: ischnaspis_longirostris \n",
      "\tClass index: 9 Class label: mictis_longicornis \n",
      "\tClass index: 10 Class label: neomelicharia_sparsa \n",
      "\tClass index: 11 Class label: normal \n",
      "\tClass index: 12 Class label: orthaga_euadrusalis \n",
      "\tClass index: 13 Class label: procontarinia_matteiana \n",
      "\tClass index: 14 Class label: procontarinia_rubus \n",
      "\tClass index: 15 Class label: valanga_nigricornis \n",
      "Dimensions: 7\n",
      "\tWidth: 500 Height: 333\n",
      "\tWidth: 500 Height: 375\n",
      "\tWidth: 1280 Height: 853\n",
      "\tWidth: 500 Height: 376\n",
      "\tWidth: 375 Height: 500\n",
      "\tWidth: 780 Height: 1040\n",
      "\tWidth: 1040 Height: 780\n",
      "Formats: 1\n",
      "\t JPEG\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "p.status()\n",
    "#p.remove_operation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generator\n",
    "\n",
    "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Pipeline.keras_generator at 0x166732750>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "g = p.keras_generator(batch_size=batch_size)\n",
    "#g = p.image_generator()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
    "\n",
    "You can view the output of generator manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MangoLeaf/lib/python3.7/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2f290a0ab1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/MangoLeaf/lib/python3.7/site-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36mkeras_generator\u001b[0;34m(self, batch_size, scaled, image_data_format)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.\u001b[0m  \u001b[0;31m# PR #126\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "images, labels = next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
    "\n",
    "To see the label of the first image returned by the generator you can use the array's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[0])\n",
    "print(images[0])\n",
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or preview the images using Matplotlib (the image should be a 5, according to the label information above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0].reshape(333, 500, 3), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
    "\n",
    "Training the network over 5 epochs, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
